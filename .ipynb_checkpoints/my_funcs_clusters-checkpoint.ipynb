{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook de funciones que usan los demás notebooks. Este debe contener las fuciones actualizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "def raw_to_datafr (xlsPath, xlsPathMfgCurve):\n",
    "    #imprimir a consola\n",
    "    os.write(1, b\"Inciando procesamiento de datos...\\n\")\n",
    "\n",
    "    \n",
    "    #xlsPath = 'C:/Users/mungu/Documents/DatosWTG.xlsx'\n",
    "    #xlsPath = 'C:\\\\Users\\\\ernesto\\\\Dropbox\\\\Doctorado\\\\datos\\\\DatosWTG.xlsx'\n",
    "    #xlsPathMfgCurve = 'Curva de potencia vestas 90.xlsx'\n",
    "\n",
    "    #dataVPxls = pd.read_excel(xlsPath,usecols=[0,1,2],index_col=0,names=['vViento','Pacw'])\n",
    "    dataVPxls = pd.read_excel(xlsPath,usecols=[0,1,2],index_col=0)\n",
    "    dataVPxls.columns =['vViento','Pacw']\n",
    "    #agrego la columna de potencia instantanea sin filtrar\n",
    "    #dataVPxls['Pw']= (dataVPxls.iloc[1:,1].values-dataVPxls.iloc[0:-1,1]) * np.pi*45**2\n",
    "    print('Total de registros: ' + str(len(dataVPxls)))\n",
    "    #dfMfgCurve = pd.read_excel(xlsPathMfgCurve,usecols=[0,2],index_col=0,names=['pw'])#cambio esto en la nueva version\n",
    "    dfMfgCurve = pd.read_excel(xlsPathMfgCurve,usecols=[0,2],index_col=0)\n",
    "    dfMfgCurve.columns = ['pw']\n",
    "    #marcando los datos faltantes asignando un nan a la fila completa\n",
    "    datamk = dataVPxls\n",
    "    datamk.loc[datamk.isnull().any(axis=1), :] = np.nan\n",
    "    #numero de filas sin datos\n",
    "    print('Numero de filas sin datos')\n",
    "    print(datamk.loc[datamk.isnull().any(axis=1), :].isnull().sum())\n",
    "\n",
    "    #eliminando filas con NaN. Si busco la fecha anterior debe aparecer error.\n",
    "    cleanData = datamk.dropna()\n",
    "\n",
    "    ###calculando la potencia\n",
    "    #la pontencia del archivo de excel es la densidad de potencia acumulada.\n",
    "    #Se tiene que hacer la resta de la potencia siguiente a la anterio y multiplicar por pi*r^2\n",
    "    #el radio es 45m\n",
    "    #si se hace la resta con un array de numpy (values) si se puede restar \n",
    "    #pues se hace elemento por elemento\n",
    "    dataVP = cleanData.drop('Pacw',axis=1)\n",
    "    dataVP['Pw']= (cleanData.iloc[1:,1].values-cleanData.iloc[0:-1,1]) * np.pi*45**2\n",
    "\n",
    "    #eliminar el ultimo valor pues es NaN\n",
    "    dataVP.drop(dataVP.tail(1).index,inplace=True) \n",
    "\n",
    "    #Eliminando outliers\n",
    "    dataVP.drop([pd.to_datetime('2016-03-07 09:50:00')],inplace=True)\n",
    "    #agregado para el reporte\n",
    "    dataVP.drop([pd.to_datetime('2016-03-08 09:00:00')],inplace=True)\n",
    "    dataVP.drop([pd.to_datetime('2016-01-02 06:40:00')],inplace=True)\n",
    "    dataVP.drop([pd.to_datetime('2016-05-05 07:20:00')],inplace=True)\n",
    "    dataVP.drop([pd.to_datetime('2016-05-23 23:00:00')],inplace=True)\n",
    "\n",
    "\n",
    "    #leyendo la direccion del viento\n",
    "    #dataDirVxls = pd.read_excel(xlsPath,sheet_name=1, usecols=[0,1],index_col=0,names=['Dir'])\n",
    "    dataDirVxls = pd.read_excel(xlsPath,sheet_name=1, usecols=[0,1],index_col=0)\n",
    "    dataDirVxls.columns =['Dir']\n",
    "    #limpiando datos\n",
    "    #marcando los datos faltantes asignando un nan a la fila completa\n",
    "    datamkdir = dataDirVxls\n",
    "    datamkdir.loc[datamkdir.isnull().any(axis=1), :] = np.nan\n",
    "    #eliminando filas con NaN. Si busco la fecha anterior debe aparecer error.\n",
    "    #tambien elimino el ultimo valor como lo hice en los datos de v y p\n",
    "    #el copy es para que no me de la copy warning\n",
    "    dataDir = datamkdir.dropna().copy()\n",
    "    dataDir.drop(dataDir.tail(1).index,inplace=True) \n",
    "    #eliminando del outlier de viento misma fecha que el de la pontencia\n",
    "    dataDir.drop([pd.to_datetime('2016-03-07 09:50:00')],inplace=True)\n",
    "    #agregado para el reporte\n",
    "    dataDir.drop([pd.to_datetime('2016-03-08 09:00:00')],inplace=True)\n",
    "    dataDir.drop([pd.to_datetime('2016-01-02 06:40:00')],inplace=True)\n",
    "    dataDir.drop([pd.to_datetime('2016-05-05 07:20:00')],inplace=True)\n",
    "    dataDir.drop([pd.to_datetime('2016-05-23 23:00:00')],inplace=True)\n",
    "\n",
    "    direcvrad= np.deg2rad(dataDir['Dir'].values)\n",
    "    velocidades = dataVP.iloc[:]['vViento'].values\n",
    "    vecVel = [-np.sin(direcvrad)*velocidades,np.cos(direcvrad)*velocidades]\n",
    "    vecVelnp=np.array(vecVel).transpose()\n",
    "    #original sin timestamp\n",
    "    #dfVecVel = pd.DataFrame(data=vecVelnp,columns=['vx','vy']\n",
    "    #con timestamp\n",
    "    dfVecVel = pd.DataFrame(data=vecVelnp,columns=['vx','vy'],index=dataVP.index)\n",
    "\n",
    "    #datos direccion velocidad\n",
    "    #print(len(dataVP))\n",
    "    #print(len(dataDir))\n",
    "    #dataDV = pd.concat([dataDir,dataVP.vViento],axis=1)\n",
    "    dataVDP = pd.concat([dataVP.vViento,dataDir,dataVP.Pw],axis=1)\n",
    "    #dataVcD =pd.concat([dataDir,dfVecVel],axis=1)\n",
    "    #Datos en p.u.. Divido todos los datos entre el máximo del conjunto de datos\n",
    "\n",
    "\n",
    "    #OPERATIONAL DATA\t\n",
    "    # Rated power\n",
    "    # 2,000 kW/2,200 kW\n",
    "    # Cut-in wind speed\t4 m/s\n",
    "    # Cut-out wind speed\t25 m/s\n",
    "    # Re cut-in wind speed\t23 m/s\n",
    "\n",
    "    cutin_speed = 4\n",
    "    cutoff_speed = 25#segun el datasheet\n",
    "    recutin_speed= 23\n",
    "    os.write(1, b\"Fin del procesamiento de datos\\n\")\n",
    "    return [dataVDP,dfVecVel,dfMfgCurve]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear plot interactivo para cluster y subcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T00:06:38.582027Z",
     "start_time": "2021-11-23T00:06:37.029134Z"
    },
    "code_folding": [
     109,
     130,
     178,
     253,
     328,
     361,
     391,
     421
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "    -Eliminar datavp\n",
    "    -Dibujar subcluster en vviento y clusters en potencia(antes busqueda con kdtree)\n",
    "    -arreglar mapa de colores\n",
    "    -quitar selfs innecesarios\n",
    "    -quite el boton guardar porque savefig solo funciona antes del .show(), por lo que solo\n",
    "        puedo guardar cuando creo el plot y no cuando lo actualizo\n",
    "    -diferente al script v2, este es el v3\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RadioButtons, TextBox\n",
    "from IPython.display import display as wgdisplay\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import datetime\n",
    "from matplotlib.ticker import EngFormatter\n",
    "import matplotlib.patheffects as path_effects #efectos de texto\n",
    "from matplotlib import rc, font_manager\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "plt.style.use('seaborn-white')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "class plotSubClusterInt:\n",
    "    '''\n",
    "    Descripcion:\n",
    "    Clase para dibujar dos subplots, uno vx vs vy y otro vviento vs Pw.\n",
    "\n",
    "    Metodos:\n",
    "        createPlot: Construye el plot de matplotlib.\n",
    "            self.dfclvv: dataframe multiindice con dos columnas vx y vy agrupadas por cluster \n",
    "            dfclpw: dataframe multiindice con dos columnas vviento y Pw agrupadas por cluster\n",
    "            cl_method: string que almacena el metodo usado para hacer el cluster\n",
    "                     |   C1    |   C2   |...\n",
    "                    ----------------------\n",
    "            Timestamp|  vx vy  |  vx vy |...            datavp: dataframe original de los datos de \n",
    "\n",
    "        updatePlot: actuliza el plot en \"tiempo real\" segun los valores de los controles\n",
    "\n",
    "        onClick: Es el la funcion que esta ligada al click en el plot. Solo ejecuta annotatePlot.\n",
    "\n",
    "        annotatePlot: Crea una anotacion en el plot que indica donde el nombre del cluster mas cercano al conjunto de\n",
    "              coordenadas donde se hizo click en el plot VP. Ademas muestra el cluster en el plot VV.\n",
    "\n",
    "        blinkCluster: Resalta el cluster al que se hace referencia.\n",
    "\n",
    "    Argumentos:\n",
    "        cl_scl_order: el orden en que se hicieron los clusters (viento,viento), (viento,potencia),\n",
    "            (potencia,viento),(potencia,potencia)\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        from colorsys import hls_to_rgb\n",
    "#         try:\n",
    "#             self.fignum = plt.gcf().number +1\n",
    "#         except Exception as e: \n",
    "#             print(e)\n",
    "#             warnings.warn('¿La libreria de matplotlib esta definida como plt?')\n",
    "#             self.fignum=999\n",
    "        self.fignum=999\n",
    "        self.fisize = (5, 5)\n",
    "        self.fontsize = 13\n",
    "        self.labelFontSize = 13\n",
    "        self.tickFontSize = 12\n",
    "        self.markerSize = 100\n",
    "        self.fontNameLabel = {'fontname':'Times New Roman'}\n",
    "        self.fontNameCluster = {'fontname':'Arial'}\n",
    "        self.ticks_font = font_manager.FontProperties(family='Times New Roman', style='normal',\n",
    "            size=self.labelFontSize, weight='normal', stretch='normal')        \n",
    "        self.n_subclu = 0\n",
    "        colors1 = plt.cm.tab20(np.linspace(0., 1, 20))\n",
    "        colors2 = plt.cm.Spectral(np.linspace(0, 1, 10))\n",
    "        colorstab = np.vstack((colors1, colors2))\n",
    "        self.mapa_colores=colorstab        \n",
    "\n",
    "    def createPlot(self, dfclvv, dfclvp,datavp,figsize=(5, 5), cl_scl_order=('viento', 'viento'), \n",
    "                   idx_centroids=[],idx_centroids_sc=[],fign=999, savepath='', showCent =True,\n",
    "                  showlBetz = True,showMfgCurve=True, showOpt = 'Magnitud',dfMfgCurve=None,\n",
    "                  showLegends = True):\n",
    "        self.fisize = figsize\n",
    "        self.dfclvv = dfclvv\n",
    "        self.datavp = datavp\n",
    "        self.dfMfgCurve=dfMfgCurve\n",
    "        if not self.dfMfgCurve.empty:\n",
    "            os.write(1,b'Manufacturer power curve missing')\n",
    "        self.showLegends = showLegends\n",
    "        self.cl_scl_order = cl_scl_order\n",
    "        self.n_clusters = len(self.dfclvv.columns.levels[0])\n",
    "        self.dfclvp =dfclvp\n",
    "        self.n_tot_clusters =self.n_clusters \n",
    "        self.fignum =fign\n",
    "        self.idx_centroids =idx_centroids\n",
    "        self.idx_centroids_sc= idx_centroids_sc\n",
    "        self.savepath = savepath\n",
    "        self.showlBetz = showlBetz # show Betz's limit\n",
    "        self.showCent = showCent # show clusters centroids\n",
    "        self.showMfgCurve = showMfgCurve #show manufacturer's curve\n",
    "        #which value is shown in the plot magnitude,cluster number,cluster name, none\n",
    "        self.showOpts = showOpt \n",
    "        ######  limite de betz\n",
    "        A=np.pi*45**2\n",
    "        Cp = 0.59 #limite de Betz\n",
    "        rho = 1.1349\n",
    "        self.vvento = np.unique(datavp.vViento.values)\n",
    "        self.PMaxViento = 1/2*rho*A*self.vvento**3*Cp\n",
    "        \n",
    "\n",
    "########## CREAR NOMBRE DE COLUMNAS\n",
    "        \n",
    "        if len(self.dfclvp.columns.levshape) == 3:  # existen subclusters , sino seria 2\n",
    "\n",
    "            self.n_subclu = len(self.dfclvv.columns.levels[1])\n",
    "            #numero total de clusters incluidos los subclusters\n",
    "            self.n_tot_clusters = self.n_subclu*self.n_clusters \n",
    "            # solo aplica cuando hay subclusters\n",
    "            lev0 = self.dfclvv.columns.get_level_values(0)\n",
    "            lev1 = self.dfclvp.columns.get_level_values(1)\n",
    "            namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "            #self.clnames_all = sorted(namcl[::2]) #todos los clusters y subclusters disponibles\n",
    "            self.clnames_all = namcl[::2] #todos los clusters y subclusters disponibles\n",
    "            #ordenar\n",
    "            vv = [self.idx_centroids_sc.loc[c].vViento for c in self.clnames_all]\n",
    "            idx = np.argsort(vv)\n",
    "            x=[self.clnames_all[i] for i in idx]\n",
    "            self.clnames_all=x.copy()\n",
    "            del(x)\n",
    "            #nombre de los clusters disponibles sin el nombre de los subclusters\n",
    "            #self.cl_avail =sorted(set(item[0] for item in self.clnames_all))\n",
    "            self.cl_avail =set(item[0] for item in self.clnames_all)\n",
    "\n",
    "        else:  # no hay subcluster\n",
    "           #lista ordenada con numeros y letras\n",
    "            self.clnames_all=sorted(dfclvv.columns.levels[0], key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))  \n",
    "            #self.cl_avail =sorted(set(item for item in self.clnames_all))\n",
    "            self.cl_avail =set(item for item in self.clnames_all)\n",
    "        \n",
    "\n",
    "        #### BUSCAR MINIMOS Y MAXIMOS GLOBALES  (hacerlo más elegante)\n",
    "        l=[self.dfclvv[cl].min() for cl in self.clnames_all]\n",
    "        self.vxminGlob,self.vyminGlob =   np.amin(l,axis=0)\n",
    "        l=[self.dfclvv[cl].max() for cl in self.clnames_all]\n",
    "        self.vxmaxGlob,self.vymaxGlob =   np.amax(l,axis=0)\n",
    "        l=[self.dfclvp[cl].min() for cl in self.clnames_all]\n",
    "        self.vvminGlob,self.pminGlob =   np.amin(l,axis=0)\n",
    "        l=[self.dfclvp[cl].max() for cl in self.clnames_all]\n",
    "        self.vvmaxGlob,self.pmaxGlob =   np.amax(l,axis=0)\n",
    "        \n",
    "        # ############### WIDGETS #################\n",
    "        self.btnUpdate = widgets.Button(description='Actualizar')\n",
    "        self.btnUpdate.on_click(self.updatePlot)\n",
    "        self.btnSelAllChk = widgets.Button(description='Sel. todo')\n",
    "        self.btnSelAllChk.on_click(self.selAllChk)\n",
    "        self.btnSelNoneChk = widgets.Button(description='Des. todo')\n",
    "        self.btnSelNoneChk.on_click(self.selNoneChk)\n",
    "        self.wdgPSize = widgets.IntSlider(\n",
    "            value=2,\n",
    "            min=1,\n",
    "            max=20,\n",
    "            step=1,\n",
    "            description='Point size:',\n",
    "            continuous_update=False)\n",
    "        self.chkLimGlob = widgets.Checkbox(\n",
    "            value=True, description='Límites Globales')\n",
    "        self.chkShowCnt = widgets.Checkbox(\n",
    "            value=self.showCent, description='Mostrar centroides')\n",
    "        self.chkShowBetz = widgets.Checkbox(\n",
    "            value=self.showlBetz, description='Mostrar línea Betz')\n",
    "        self.chkShowCPotFab = widgets.Checkbox(\n",
    "            value=self.showMfgCurve, description='Mostrar curva Fab.')\n",
    "        self.tbreta = widgets.IntText(\n",
    "            value=0, description='Retardo:', layout=Layout(width='90%', height='80px'))\n",
    "        self.wradText = widgets.RadioButtons(\n",
    "            options=['Magnitud', 'Numero', 'Clusters', 'Ninguno'],\n",
    "            description='Mostrar texto:')\n",
    "        self.wradText.value='Numero'\n",
    "        figsavepath = self.savepath\n",
    "        figsavename = 'VVVPCl'+str(self.n_clusters)+'SCl'+str(self.n_subclu)+'_'\n",
    "        figsavetime = datetime.datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S_%f\")\n",
    "        self.tbFilePath = widgets.Text(\n",
    "            value=figsavepath+figsavename+figsavetime+'.png',\n",
    "            description='Save path:', layout=Layout(width='90%', height='80px'))\n",
    "        #self.chkShowCnt.observe(self.updatePlot, 'value')\n",
    "        #self.wdgPSize.observe(self.updatePlot, 'value')\n",
    "        #self.wradText.observe(self.updatePlot, 'value')\n",
    "        #self.chkShowBetz.observe(self.updatePlot, 'value')\n",
    "        #self.chkShowCPotFab.observe(self.updatePlot, 'value')\n",
    "\n",
    "      \n",
    "        self.wchkcls=[] #lista de checbox con los nombresde los clusters\n",
    "        n=1#para numerar la lista de clusters\n",
    "        for i in range(len(self.clnames_all)):\n",
    "            self.wchkcls.append(widgets.Checkbox(\n",
    "                    value=True, description=str(n) +'-' +str(self.clnames_all[i])))\n",
    "            n+=1\n",
    "        box_layout = Layout(display='flex',\n",
    "                            flex_flow='column',\n",
    "                            align_items='stretch',\n",
    "                            height='200px',\n",
    "                            )    \n",
    "        vbchkcls = widgets.VBox(self.wchkcls, layout=box_layout)\n",
    "        \n",
    "\n",
    "        # WIDGETS EN CAJAS ----------------------\n",
    "        vbopt1 = widgets.VBox([self.chkShowCnt,self.chkShowBetz, self.chkShowCPotFab,self.chkLimGlob, self.tbreta])\n",
    "        vbopt2 = widgets.VBox([self.wradText, self.wdgPSize ])\n",
    "        vbButtons = widgets.VBox([self.btnSelAllChk,self.btnSelNoneChk, self.btnUpdate, self.tbFilePath])\n",
    "        items = [vbButtons, vbchkcls,vbopt1,vbopt2 ]\n",
    "        hb = widgets.HBox(items)\n",
    "        wgdisplay(hb)\n",
    "        #para que la potencia quede como 1, 1k, 1M\n",
    "        self.formatterPw = EngFormatter(places=1, sep=\"\\N{THIN SPACE}\")  # U+2009\n",
    "\n",
    "        plt.ion()\n",
    "        self.fig = plt.figure(self.fignum, figsize=self.fisize)\n",
    "\n",
    "        self.axvv = self.fig.add_subplot(121)\n",
    "        self.axvp = self.fig.add_subplot(122)\n",
    "        self.axvp.yaxis.set_major_formatter(self.formatterPw)\n",
    "\n",
    "        self.updatePlot(1)\n",
    "    \n",
    "    def selAllChk(self,val):\n",
    "        for item in self.wchkcls:\n",
    "            item.value=True\n",
    "    def selNoneChk(self,val):\n",
    "        for item in self.wchkcls:\n",
    "            item.value=False       \n",
    "    def savePlot(self,val):\n",
    "        figsavepath = self.savepath\n",
    "        figsavename = 'VVVPCl'+str(self.n_clusters)+'SCl'+str(self.n_subclu)+'_'\n",
    "        figsavetime = datetime.datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S_%f\")\n",
    "        self.tbFilePath.value=figsavepath+figsavename+figsavetime+'.png'\n",
    "        plt.savefig(  self.tbFilePath.value, bbox_inches='tight', pad_inches=0.1)\n",
    "        print('Saved in ' +  self.tbFilePath.value)\n",
    "    \n",
    "    def updatePlot(self, val):\n",
    "        pSize = self.wdgPSize.value\n",
    "        self.axvv.axes.clear()\n",
    "        self.axvp.axes.clear()\n",
    "        self.axvv.grid()\n",
    "        self.axvp.grid()\n",
    "        if len(self.dfclvp.columns.levshape) == 3:  # existen subclusters , sino seria 2\n",
    "            clnames= [eval(el.description.split('-')[1]) for el in self.wchkcls if el.value==True]\n",
    "            #ordenar subclusters por velocidad\n",
    "            #los subclusters se ordenan dentro de cada grupo de clusters en idx_centrods_sc\n",
    "            #hay que ordenarlos tambien globalmente y no solo localmente\n",
    "            #self.cl_avail =sorted(set(item[0] for item in clnames))\n",
    "            vv = [self.idx_centroids_sc.loc[c].vViento for c in clnames]\n",
    "            idx = np.argsort(vv)\n",
    "            x=[clnames[i] for i in idx]\n",
    "            clnames=x.copy()\n",
    "            del(x)\n",
    "            #self.clnames_all =clnames# REV: SE OCUPA CLNAMES_ALL???\n",
    "            self.cl_avail =set(item[0] for item in clnames)\n",
    "\n",
    "        else :\n",
    "            clnames=[el.description.split('-')[1] for el in self.wchkcls if el.value==True]\n",
    "            #aqui tambien va por si se eliminan todos los subclusters del mismo cluster. Solo lista los clusters\n",
    "            #self.cl_avail =sorted(set(item for item in clnames))\n",
    "            self.cl_avail =set(item for item in clnames)\n",
    "        \n",
    "        \n",
    "        # DEFINIR LIMITES DE PLOT\n",
    "\n",
    "        #buscar los minimos y maximos de los clusters\n",
    "        #debede haber una forma mas elegante de hacerlo. Como hago sliced elmultiindex con tuplas\n",
    "\n",
    "        lvxmin=np.empty(self.n_tot_clusters)\n",
    "        lvxmin.fill(np.nan)\n",
    "        lvymin=np.empty(self.n_tot_clusters)\n",
    "        lvymin.fill(np.nan)\n",
    "        lvxmax=np.empty(self.n_tot_clusters)\n",
    "        lvxmax.fill(np.nan)\n",
    "        lvymax=np.empty(self.n_tot_clusters)\n",
    "        lvymax.fill(np.nan)\n",
    "        lvvmin=np.empty(self.n_tot_clusters)\n",
    "        lvvmin.fill(np.nan)\n",
    "        lvvmax=np.empty(self.n_tot_clusters)\n",
    "        lvvmax.fill(np.nan)\n",
    "        lpmin =np.empty(self.n_tot_clusters)\n",
    "        lpmin.fill(np.nan)\n",
    "        lpmax= np.empty(self.n_tot_clusters)\n",
    "        lpmax.fill(np.nan)\n",
    "        n=0\n",
    "        for cl in clnames:\n",
    "\n",
    "            lvxmin[n],lvymin[n]= self.dfclvv[cl].min()\n",
    "            lvxmax[n],lvymax[n] = self.dfclvv[cl].max()\n",
    "            lvvmin[n],lpmin[n] = self.dfclvp[cl].min()\n",
    "            lvvmax[n],lpmax[n] = self.dfclvp[cl].max()           \n",
    "            n+=1\n",
    "        vxmin=np.nanmin(lvxmin)\n",
    "        if np.isnan(vxmin):\n",
    "            vxmin=0\n",
    "        vymin = np.nanmin(lvymin)\n",
    "        if np.isnan(vymin):\n",
    "            vymin =0\n",
    "        vxmax = np.nanmax(lvxmax)\n",
    "        if np.isnan(vxmax):\n",
    "            vxmax=1\n",
    "        vymax = np.nanmax(lvymax)\n",
    "        if np.isnan(vymax):\n",
    "            vymax=1\n",
    "        vvmin = np.nanmin(lvvmin)\n",
    "        if np.isnan(vvmin):\n",
    "            vvmin=0\n",
    "        vvmax = np.nanmax(lvvmax)\n",
    "        if np.isnan(vvmax):\n",
    "            vvmax=1\n",
    "        pmin= np.nanmin(lpmin)\n",
    "        if np.isnan(pmin):\n",
    "            pmin=0\n",
    "        pmax = np.nanmax(lpmax)\n",
    "        if np.isnan(pmax):\n",
    "            pmax=1\n",
    "        if self.chkLimGlob.value:#plotear con limites globales o con los limites del cluster\n",
    "            self.axvv.set_xlim((self.vxminGlob, self.vxmaxGlob))\n",
    "            self.axvv.set_ylim((self.vyminGlob, self.vymaxGlob))\n",
    "            self.axvp.set_xlim((self.vvminGlob, self.vvmaxGlob))\n",
    "            self.axvp.set_ylim((self.pminGlob, self.pmaxGlob))\n",
    "        else:    \n",
    "            self.axvv.set_xlim((vxmin, vxmax))\n",
    "            self.axvv.set_ylim((vymin, vymax))\n",
    "            self.axvp.set_xlim((vvmin, vvmax))\n",
    "            self.axvp.set_ylim((pmin, pmax))\n",
    "\n",
    "\n",
    "# ########################## PLOTEAR ########################\n",
    "        \n",
    "\n",
    "        for item in clnames:\n",
    "            #busca el cluster actual y devuelve el indice dentro de la lista de clusters donde lo encuentra\n",
    "            #es decir, asocia un numero unico a un nombre de cluster\n",
    "            #es para que el color de los clusters sea el mismo siempre\n",
    "            idxClName = [ncl_ for ncl_, clname_ in enumerate(self.clnames_all) if clname_ == item]\n",
    "            #self.fig.suptitle('Grupos de velocidad de viento y potencia', y=1)\n",
    "            # magnitud del vector\n",
    "\n",
    "            magni = round(\n",
    "                np.mean(\n",
    "                    np.sqrt(self.dfclvv[item].vx**2 +\n",
    "                            self.dfclvv[item].vy**2)),\n",
    "                1)  # magnitud de la vv\n",
    "\n",
    "            self.axvv.scatter(\n",
    "                self.dfclvv[item].vx,\n",
    "                self.dfclvv[item].vy,\n",
    "                s=pSize,\n",
    "                c=self.mapa_colores[idxClName],\n",
    "                alpha=1)\n",
    "\n",
    "            self.axvp.scatter(\n",
    "                self.dfclvp[item].vViento,\n",
    "                self.dfclvp[item].Pw,\n",
    "                s=pSize,\n",
    "                c=self.mapa_colores[idxClName])\n",
    "            #para que el label de la potencia quede como 1,1k,1M\n",
    "            self.axvp.yaxis.set_major_formatter(self.formatterPw)\n",
    "            \n",
    "#             self.axvp.ticklabel_format(\n",
    "#                 style='sci', axis='y', scilimits=(0, 0), useMathText=True)\n",
    "          \n",
    "        ####### MOSTRAR TEXTO ################################################################\n",
    "            if self.wradText.index == 0: #magnitud\n",
    "                \n",
    "                text = self.axvv.text(\n",
    "                    self.dfclvv[item].vx.mean(),\n",
    "                    self.dfclvv[item].vy.mean(),\n",
    "                    magni,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                       path_effects.Normal()])\n",
    "\n",
    "                text = self.axvp.text(\n",
    "                    self.dfclvp[item].vViento.mean(),\n",
    "                    self.dfclvp[item].Pw.mean(),\n",
    "                    magni,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                       path_effects.Normal()])\n",
    "                \n",
    "            elif self.wradText.index == 1: #numero\n",
    "                text = self.axvv.text(\n",
    "                    self.dfclvv[item].vx.mean(),\n",
    "                    self.dfclvv[item].vy.mean(),\n",
    "                    idxClName[0]+1,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                       path_effects.Normal()])\n",
    "\n",
    "\n",
    "                text = self.axvp.text(\n",
    "                    self.dfclvp[item].vViento.mean(),\n",
    "                    self.dfclvp[item].Pw.mean(),\n",
    "                    idxClName[0]+1,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                       path_effects.Normal()])\n",
    "            \n",
    "            elif self.wradText.index == 2:\n",
    "                text = self.axvv.text(\n",
    "                    self.dfclvv[item].vx.mean(),\n",
    "                    self.dfclvv[item].vy.mean(),\n",
    "                    item,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                       path_effects.Normal()])\n",
    "\n",
    "\n",
    "                text = self.axvp.text(\n",
    "                    self.dfclvp[item].vViento.mean(),\n",
    "                    self.dfclvp[item].Pw.mean(),\n",
    "                    item,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                       path_effects.Normal()])\n",
    "            self.fig.canvas.draw()\n",
    "            \n",
    "        \n",
    "######### MOSTRAR CENTROIDES#######################\n",
    "        if self.chkShowCnt.value == True:\n",
    "            \n",
    "            \n",
    "            for cl in self.cl_avail:\n",
    "                \n",
    "                #el nombred el cluster esta en el indice\n",
    "                #le quito la letra con cl[1:] y dejo solo el numero como\n",
    "                #esta en el dataframe\n",
    "                numcl = int(cl[1:])\n",
    "                self.axvv.scatter(\n",
    "                        self.idx_centroids.loc[numcl].vx,\n",
    "                        self.idx_centroids.loc[numcl].vy,\n",
    "                        marker='X',\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1,\n",
    "                        facecolor='yellow',\n",
    "                        s=self.markerSize)\n",
    "                self.axvp.scatter(\n",
    "                    self.idx_centroids.loc[numcl].vViento,\n",
    "                    self.idx_centroids.loc[numcl].Pw,\n",
    "                    marker='X',\n",
    "                    edgecolor='black',\n",
    "                    linewidth=1,\n",
    "                    facecolor='yellow',\n",
    "                    s=self.markerSize)\n",
    "                \n",
    "####### MOSTRAR CENTROIDES SUBCLUSTERS\n",
    "            if self.n_subclu > 0:               \n",
    "                for el in clnames:\n",
    "                    self.axvv.scatter(\n",
    "                        self.idx_centroids_sc.loc[el].vx,\n",
    "                        self.idx_centroids_sc.loc[el].vy,\n",
    "                        marker='h',\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1,\n",
    "                        facecolor='aqua',\n",
    "                        s=self.markerSize)\n",
    "                    self.axvp.scatter(\n",
    "                        self.idx_centroids_sc.loc[el].vViento,\n",
    "                        self.idx_centroids_sc.loc[el].Pw,\n",
    "                        marker='h',\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1,\n",
    "                        facecolor='aqua',\n",
    "                        s=self.markerSize)\n",
    "### MOSTRAR OTRAS REFERENCIAS\n",
    "#MOSTRAR LEYENDA\n",
    "    #no programado    \n",
    "        #self.axvv.legend(scatterpoints=1)\n",
    "#MOSTRAR CURVA DEL FABRICANTE\n",
    "        if self.chkShowCPotFab.value==True:\n",
    "            self.axvp.plot(self.dfMfgCurve.index, self.dfMfgCurve.pw, c='red', label='Manufacturer')\n",
    "\n",
    "#MOSTRAR LIMITE DE BETZ\n",
    "        if self.chkShowBetz.value==True:\n",
    "            self.axvp.plot(self.vvento,self.PMaxViento,label='Betz',c='y')\n",
    "        \n",
    "        #self.fig.legend(loc=best)\n",
    "        self.axvp.set_xlabel('Wind Speed [m/s]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "        self.axvp.set_ylabel('Power [W]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "        self.axvv.set_xlabel('vx [m/s]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "        self.axvv.set_ylabel('vy [m/s]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "        self.axvv.tick_params(axis='both', which='major')\n",
    "        self.axvp.tick_params(axis='both', which='major')\n",
    "        #con esto cambio el texto de las thicks a el que defino en self.tick_font\n",
    "        for label in self.axvv.get_xticklabels():\n",
    "            label.set_fontproperties(self.ticks_font)\n",
    "        for label in self.axvv.get_yticklabels():\n",
    "            label.set_fontproperties(self.ticks_font)\n",
    "        for label in self.axvp.get_xticklabels():\n",
    "            label.set_fontproperties(self.ticks_font)\n",
    "        for label in self.axvp.get_yticklabels():\n",
    "            label.set_fontproperties(self.ticks_font)\n",
    "        \n",
    "        #manual legends\n",
    "        if self.showLegends:\n",
    "            legCentroids = mlines.Line2D([], [], color='yellow', marker='X', linestyle='None',\n",
    "                          markersize=10, label='Centroids',markeredgecolor='black',markeredgewidth=1.5)\n",
    "            \n",
    "           \n",
    "            if self.n_subclu > 0:  \n",
    "                legSecCentroids = mlines.Line2D([], [], color='aqua', marker='h', linestyle='None',\n",
    "                          markersize=10, label='Sec. centroids',markeredgecolor='black',markeredgewidth=1)\n",
    "                self.axvp.legend(handles=[legCentroids, legSecCentroids],facecolor = 'gainsboro', frameon=True)\n",
    "                self.axvv.legend(handles=[legCentroids, legSecCentroids],facecolor = 'gainsboro',frameon=True)\n",
    "            else:\n",
    "                self.axvv.legend(handles=[legCentroids],facecolor = 'gainsboro',frameon=True)\n",
    "                self.axvp.legend(handles=[legCentroids],facecolor = 'gainsboro',frameon=True)\n",
    "    \n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        self.fig.canvas.flush_events()\n",
    "        plt.gcf()\n",
    "        self.savePlot(val)\n",
    "        self.fig.canvas.draw()\n",
    "        #imprimir a consola\n",
    "        os.write(1, b\"Plot actualizado\\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# cluster to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''TO DO: en el idx_centroids los numeros de los clusters no llevan la C, en el idx_centroids_sc si\n",
    "la llevan, o cambiar todo a que la lleven o que no la lleven'''\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from scipy.spatial.distance import cdist\n",
    "#crear dataframes a partir de clusters\n",
    "#def cluster2DataFrame(dfvxvy, dfVP, n_clusters, labels, n_subclu=0, clusters='viento',subclusters='viento'):\n",
    "def cluster2DataFrame(dfvxvy, dfVP, n_clusters, n_subclu=0, clusters='viento',subclusters='viento',datadir=[]):\n",
    "    '''\n",
    "        Descriapcion: \n",
    "        Esta funcion toma diferentes dataframes de entrada agrupa los datos por cluster.\n",
    "        \n",
    "        Argumento:\n",
    "        dfvxvy: dataframe con columnas vx y vy\n",
    "        dfVP: dataframe con columnas de magnitud de viento y potencia\n",
    "        n_clusters: numero de clusters\n",
    "        labels: etiquetas del metodo de clusterizacion\n",
    "        n_subclu: Número de suclusters a calcular a partir de los n clusters calculados en un principio.\n",
    "                  Si n_subclu=0 no se calcula ningun subcluster. Por defecto n_sub=0\n",
    "        \n",
    "        Devuelve:\n",
    "        cl_ord: un array que contiene el número de cluster n ordenado de menor a mayor\n",
    "            de las magnitudes de la velocidad de viento sin tomar en cuenta la direccion\n",
    "        dfclvv: dataframe donde las componentes de velocidad de viento vx y vy estan\n",
    "            agrupadas por cluster\n",
    "        dfclpw: dataframe donde la potencia esta agrupada por cluster\n",
    "        dfclvp: dataframe donde la potencia y la magnitud de viento esta agrupada por\n",
    "            cluster\n",
    "    '''\n",
    "#'''- KMEANS -----------------------------------------------------------------------------------------'''\n",
    "    if clusters=='viento':\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(dfvxvy)\n",
    "        cl_centroids = kmeans.cluster_centers_\n",
    "        cl_labels=kmeans.labels_ \n",
    "        clusassign=cl_labels#si nos e usa untrained data\n",
    "        ncentroids = len(cl_centroids)\n",
    "        #buscar centroides en dataframes\n",
    "        #https://stackoverflow.com/questions/42583995/get-the-centroid-row-index-from-k-means-clustering-using-sklearn\n",
    "        #clusassign = kmeans.fit_predict(dfvxvy.values)#solo se si utiliza untrained data\n",
    "        min_dist = np.min(cdist(dfvxvy.values, kmeans.cluster_centers_, 'euclidean'), axis=1)#distancia minima a cada centroide\n",
    "        Y = pd.DataFrame(min_dist, index=dfvxvy.index, columns=['PCTimeStamp'])\n",
    "        Z = pd.DataFrame(clusassign, index=dfvxvy.index, columns=['cluster_ID'])\n",
    "        #crea el dataframe\n",
    "        PAP = pd.concat([Y,Z], axis=1)\n",
    "        \n",
    "    elif clusters=='potencia':\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(dfVP)\n",
    "        cl_centroids = kmeans.cluster_centers_\n",
    "        cl_labels=kmeans.labels_ \n",
    "        ncentroids = len(cl_centroids)\n",
    "        #clusassign=cl_labels\n",
    "        #buscar centroides en dataframes\n",
    "        #clusassign = kmeans.fit_predict(dfVP.values)\n",
    "        min_dist = np.min(cdist(dfVP.values, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "        Y = pd.DataFrame(min_dist, index=dfVP.index, columns=['PCTimeStamp'])\n",
    "        Z = pd.DataFrame(clusassign, index=dfVP.index, columns=['cluster_ID'])\n",
    "        PAP = pd.concat([Y,Z], axis=1)\n",
    "    elif clusters=='direccion':\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(datadir)\n",
    "        cl_centroids = kmeans.cluster_centers_\n",
    "        cl_labels=kmeans.labels_ \n",
    "        #clusassign=cl_labels\n",
    "        ncentroids = len(cl_centroids)\n",
    "        #buscar centroides en dataframes\n",
    "        #clusassign = kmeans.fit_predict(dfVP.values)\n",
    "        min_dist = np.min(cdist(dfVP.values, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "        Y = pd.DataFrame(min_dist, index=dfVP.index, columns=['PCTimeStamp'])\n",
    "        Z = pd.DataFrame(clusassign, index=dfVP.index, columns=['cluster_ID'])\n",
    "        PAP = pd.concat([Y,Z], axis=1)\n",
    "    \n",
    "    #ordend e los cluster por magnitud de vv\n",
    "    cl_magni = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        vx = dfvxvy.vx.values[cl_labels == i]\n",
    "        vy = dfvxvy.vy.values[cl_labels == i]\n",
    "        cl_magni[i] = np.mean(np.sqrt(vx**2 + vy**2))  #magnitud de la vv\n",
    "    cl_ord = np.argsort(cl_magni.argsort()) #ver https://github.com/numpy/numpy/issues/8757\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    grouped = PAP.groupby(['cluster_ID'])#agrupa por numero de clusters las distancias minimas\n",
    "    idx_centroids = grouped.idxmin()#encuentra el indice de la distanciam minima\n",
    "    #agregando columnas de velocidadd de viento y potencia al dataframe de los centroides\n",
    "    vxvy=dfvxvy.loc[idx_centroids.PCTimeStamp].values\n",
    "    vvpot = dfVP.loc[idx_centroids.PCTimeStamp].values\n",
    "     \n",
    "    idx_centroids=idx_centroids.assign(vx=vxvy[:,0],vy=vxvy[:,1],vViento=vvpot[:,0],Pw=vvpot[:,1]) \n",
    "    idx_centroids.sort_values(by='vViento',inplace=True)# ordenar por velocidad de viento\n",
    "    idx_centroids.reset_index(inplace=True) #que ya no sea el cluster id el indice\n",
    "    idx_centroids.index.set_names('cluster_ID_ord',inplace=True)  #ponerle el nombre al indice ordenado\n",
    "    idx_centroids.index+=1 #paraque el indice empieze en uno y no exista cluster 0\n",
    "    if clusters=='direccion':\n",
    "        \n",
    "        #SUSTITUIR CENTRODS DE DIRECCION POR VELOCIDAD\n",
    "        lc =[]\n",
    "        \n",
    "        for labcl in np.unique(cl_labels):\n",
    "        \n",
    "            lc.append(centeroidpython(dfvxvy.values[cl_labels==labcl]))\n",
    "        \n",
    "        cl_centroids=np.array([[i[0],i[1]]for i in cl_centroids])\n",
    "        #ordenar centroides\n",
    "        #cl_cenroids=cl_centroids[cl_centroids[:,0].argsort()]\n",
    "\n",
    "\n",
    "\n",
    "## CREAR MULTIINDICE ---------------------------------------------------------------'''\n",
    "    #CLUSTER VX,VY:\n",
    "    #https://stackoverflow.com/questions/37835508/how-to-do-multi-column-from-tuples\n",
    "    #nombre de las columnas del dataframe\n",
    "    colheadvv = []\n",
    "    colheadpw = []\n",
    "    for i in range(n_clusters):\n",
    "        colheadvv.append(('C' + str(i + 1), 'vx'))\n",
    "        colheadvv.append(('C' + str(i + 1), 'vy'))\n",
    "        colheadpw.append('C' + str(i + 1))\n",
    "    dfclvv = pd.DataFrame()\n",
    "        \n",
    "    for i in range(n_clusters):\n",
    "        dfclvv = pd.concat([\n",
    "            dfclvv, dfvxvy.vx[cl_labels ==np.where(cl_ord ==i)[0][0]],\n",
    "            dfvxvy.vy[cl_labels == np.where(cl_ord ==i)[0][0]]\n",
    "        ],\n",
    "                           axis=1,\n",
    "                           ignore_index=True)\n",
    "    #crear multiindice\n",
    "    dfclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "    #CLUSTER POTENCIA:\n",
    "    dfclpw = pd.DataFrame()\n",
    "    for i in range(n_clusters):\n",
    "        dfclpw = pd.concat([dfclpw, dfVP.Pw[cl_labels == np.where(cl_ord ==i)[0][0]]],\n",
    "                           ignore_index=True,\n",
    "                           axis=1)\n",
    "    dfclpw.columns = colheadpw\n",
    "\n",
    "    #CLUSTER VIENTO POTENCIA:\n",
    "    colheadvp = []\n",
    "    for i in range(n_clusters):\n",
    "        colheadvp.append(('C' + str(i + 1), 'vViento'))\n",
    "        colheadvp.append(('C' + str(i + 1), 'Pw'))\n",
    "    dfclvp = pd.DataFrame()\n",
    "    for i in range(n_clusters):\n",
    "        dfclvp = pd.concat([\n",
    "            dfclvp, dfVP.vViento[cl_labels == np.where(cl_ord ==i)[0][0]],\n",
    "            dfVP.Pw[cl_labels ==np.where(cl_ord ==i)[0][0]]] ,\n",
    "                           axis=1,\n",
    "                           ignore_index=True)\n",
    "    #crear multiindice\n",
    "    dfclvp.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "    \n",
    "    if clusters=='direccion':\n",
    "        #CLUSTER direccion viento\n",
    "        colheadvp = []\n",
    "        for i in range(n_clusters):\n",
    "            colheadvp.append(('C' + str(i + 1), 'Dir'))\n",
    "            colheadvp.append(('C' + str(i + 1), 'vViento'))\n",
    "        dfcldv = pd.DataFrame()\n",
    "        for i in range(n_clusters):\n",
    "            dfcldv = pd.concat([\n",
    "                dfcldv, datadir.vViento[cl_labels ==( cl_ord ==i)],\n",
    "                datadir.Dir[cl_labels == (cl_ord ==i)]],                               \n",
    "                axis=1,ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfcldv.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "    '''- CALCULAR SUBCLUSTERS ------------------------------------------------------------------- '''\n",
    "\n",
    "    \n",
    "    if n_subclu > 0:\n",
    "        scl_centroids = []\n",
    "        scl_labels = []\n",
    "        scl_ncentroids =[]\n",
    "        idx_centroids_sc= pd.DataFrame() #va almacenar los centroides de los subclusters\n",
    "        #obtener los resultados del clusterizado\n",
    "        for i in range(n_clusters):\n",
    "            if subclusters=='viento':\n",
    "                dfclvvnoNA=dfclvv['C'+str(i+1)].dropna()\n",
    "                #buscando centroides con los subclusters\n",
    "                kmeans_sc = cluster.KMeans(n_clusters=n_subclu, random_state=0).fit(dfclvvnoNA)\n",
    "                min_dist_sc = np.min(cdist(dfclvvnoNA.values, kmeans_sc.cluster_centers_, 'euclidean'), axis=1)\n",
    "                Y_sc = pd.DataFrame(min_dist_sc, index=dfclvvnoNA.index, columns=['PCTimeStamp'])\n",
    "                Z_sc = pd.DataFrame(kmeans_sc.labels_, index=dfclvvnoNA.index, columns=['subcluster_ID'])\n",
    "    \n",
    "            elif subclusters=='potencia':\n",
    "                dfclvpnoNA=dfclvp['C'+str(i+1)].dropna()\n",
    "                #buscando centroides con los subclusters\n",
    "                kmeans_sc = cluster.KMeans(n_clusters=n_subclu, random_state=0).fit(dfclvpnoNA)\n",
    "                min_dist_sc = np.min(cdist(dfclvpnoNA.values, kmeans_sc.cluster_centers_, 'euclidean'), axis=1)\n",
    "                Y_sc = pd.DataFrame(min_dist_sc, index=dfclvpnoNA.index, columns=['PCTimeStamp'])\n",
    "                Z_sc = pd.DataFrame(kmeans_sc.labels_, index=dfclvpnoNA.index, columns=['subcluster_ID'])\n",
    "            else:\n",
    "                print('Todavía no programado, haciendo subclusters en potencia')\n",
    "                kmeans_sc = cluster.KMeans(n_clusters=n_subclu, random_state=0).fit(dfclvp['C'+str(i+1)].dropna())\n",
    "                \n",
    "            scl_centroids.append(kmeans_sc.cluster_centers_)\n",
    "            scl_labels.append(kmeans_sc.labels_)\n",
    "            scl_ncentroids.append(len(scl_centroids[i]))\n",
    "            \n",
    "            \n",
    "            PAP_sc = pd.concat([Y_sc,Z_sc], axis=1)  \n",
    "            #poniendo index a los centroides de los subclusters\n",
    "            grouped_sc = PAP_sc.groupby(['subcluster_ID'])\n",
    "            idx_cent_sc = grouped_sc.idxmin()\n",
    "            idx_cent_sc.index +=1\n",
    "            #agregando columnas de velocidadd de viento y potencia al dataframe de los centroides\n",
    "            vxvy_sc=dfvxvy.loc[idx_cent_sc.PCTimeStamp].values\n",
    "            vvpot_sc = dfVP.loc[idx_cent_sc.PCTimeStamp].values\n",
    "            idx_centroids_sc=pd.concat([idx_centroids_sc, idx_cent_sc.assign(vx=vxvy_sc[:,0],vy=vxvy_sc[:,1],vViento=vvpot_sc[:,0],\n",
    "                                                     Pw=vvpot_sc[:,1], cluster_ID='C'+str(i+1))] )\n",
    "        #creando el multiindex fuera del ciclo for\n",
    "       # idx_centroids_sc.set_index(['cluster_ID',idx_centroids_sc.index],inplace=True)\n",
    "        \n",
    "        idx_centroids_sc.reset_index(inplace=True)\n",
    "        idx_centroids_sc.sort_values(['cluster_ID','vViento'], ascending=[1,1],inplace=True)\n",
    "        lst_num_sc=list(range(1,n_subclu+1))*n_clusters#crea una lista de numeros para el subcluster [1,2,3..1,2,3]\n",
    "        sc_idx_list =list(map(lambda x:'SC'+str(x),lst_num_sc))#le pone las letras SC [SC1,SC2,SC3...SC1,SC2,SC3]\n",
    "        idx_centroids_sc=idx_centroids_sc.assign(subcluster_ID_ord=sc_idx_list)\n",
    "        idx_centroids_sc.set_index(['cluster_ID','subcluster_ID_ord'],inplace=True)\n",
    "            \n",
    "            \n",
    "############  ORDENAR CENTROIDES:  ordenar el orden de aparicion segun la magnitud de la vv\n",
    "        scl_magni = np.zeros([n_clusters,n_subclu])\n",
    "        scl_ord = []\n",
    "        \n",
    "        for i in range(n_clusters):\n",
    "            \n",
    "            for j in range(n_subclu):\n",
    "                \n",
    "                vx = dfclvv['C' + str(i+1)].vx.dropna().values[scl_labels[i] == j]\n",
    "                vy = dfclvv['C' + str(i+1)].vy.dropna().values[scl_labels[i] == j]\n",
    "                scl_magni[i][j] = np.mean(np.sqrt(vx**2 + vy**2))  #magnitud de la vv\n",
    "                \n",
    "            scl_ord.append( scl_magni[i].argsort())# ver https://github.com/numpy/numpy/issues/8757\n",
    "        \n",
    "        #ORDENAR CENTROIDES\n",
    "        for i in range(len(scl_centroids)):\n",
    "            scl_centroids[i] = scl_centroids[i][scl_ord[i]]   \n",
    "\n",
    "            \n",
    "\n",
    "        #CLUSTER VIENTO POTENCIA:\n",
    "        colheadvp = []\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                colheadvp.append(('C' + str(i + 1),'SC' + str(j + 1), 'vViento'))\n",
    "                colheadvp.append(('C' + str(i + 1),'SC' + str(j + 1), 'Pw'))\n",
    "        dfsclvp = pd.DataFrame()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                dfsclvp = pd.concat([\n",
    "                    dfsclvp, dfclvp['C'+str(i+1)].dropna().vViento[scl_labels[i]  == scl_ord[i][j]],\n",
    "                    dfclvp['C'+str(i+1)].dropna().Pw[scl_labels[i] == scl_ord[i][j]]\n",
    "                ],\n",
    "                                   axis=1,\n",
    "                                   ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfsclvp.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "       \n",
    "        #CLUSTER VX,VY:####################################################\n",
    "        colheadvv = []\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                colheadvv.append(('C' + str(i + 1),'SC' + str(j + 1), 'vx'))\n",
    "                colheadvv.append(('C' + str(i + 1),'SC' + str(j + 1), 'vy'))\n",
    "        dfsclvv = pd.DataFrame()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                dfsclvv = pd.concat([\n",
    "                    dfsclvv, dfclvv['C'+str(i+1)].dropna().vx[scl_labels[i]  == scl_ord[i][j]],\n",
    "                    dfclvv['C'+str(i+1)].dropna().vy[scl_labels[i] == scl_ord[i][j]]\n",
    "                ],\n",
    "                                   axis=1,\n",
    "                                   ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfsclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "        \n",
    "        #CLUSTER POTENCIA:\n",
    "        dfsclpw = pd.DataFrame()\n",
    "        colheadpw =[]\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                colheadpw.append(('C' + str(i + 1),'SC' + str(j + 1)))\n",
    "       \n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                dfsclpw = pd.concat([dfsclpw, dfclvp['C'+str(i+1)].Pw.dropna()[scl_labels[i] == scl_ord[i][j]]],\n",
    "                               ignore_index=True,\n",
    "                               axis=1)\n",
    "        dfsclpw.columns = pd.MultiIndex.from_tuples(colheadpw)\n",
    "        \n",
    "        #### buscar centroides para la grafica vv\n",
    "        #obtener nombre de niveles\n",
    "        n_subclu = len(dfsclvv.columns.levels[1])\n",
    "        #numero total de clusters incluidos los subclusters\n",
    "        n_tot_clusters = n_subclu*n_clusters \n",
    "        # solo aplica cuando hay subclusters\n",
    "        lev0 = dfsclvv.columns.get_level_values(0)\n",
    "        lev1 = dfsclvv.columns.get_level_values(1)\n",
    "        namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "        colnames = namcl[::2]\n",
    "\n",
    "        \n",
    "        '''TODO: QUE EL RETURN TENGA ESTA FUNCIONALIDAD'''\n",
    "        #return  dfsclvv,dfsclpw,dfsclvp,cl_ord,cl_centroids, idx_centroids,scl_ord,scl_centroids,idx_scl_centroids\n",
    "        if clusters=='direccion':\n",
    "            return  dfsclvv,dfsclpw,dfsclvp,dfclvp,cl_ord,cl_centroids, idx_centroids,scl_ord,scl_centroids,\n",
    "\n",
    "        else:\n",
    "            return  dfsclvv,dfsclpw,dfsclvp,cl_ord,cl_centroids, idx_centroids,scl_ord,scl_centroids,idx_centroids_sc\n",
    "    \n",
    "    else:# sin subclusters\n",
    "        if clusters=='direccion':\n",
    "            print('NO PROGRAMADO')\n",
    "            return dfclvv, dfclpw, dfclvp,dfcldv,cl_ord, cl_centroids,idx_centroids\n",
    "        else:\n",
    "            scl_ord=[]\n",
    "            scl_centroids=[]\n",
    "            idx_centroids_sc=[]\n",
    "            return dfclvv,dfclpw,dfclvp,cl_ord,cl_centroids,idx_centroids,scl_ord,scl_centroids,idx_centroids_sc\n",
    "    return\n",
    "if __name__ == '__cluster2DataFrame__':\n",
    "    cluster2DataFrame(dfvxvy, dfVP, n_clusters, n_subclu=0, clusters='viento',subclusters='viento',datadir=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Eliminar clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "''' FUNCION ACTUALIZADA A AGOSTO VER: https://pandas-docs.github.io/pandas-docs-travis/user_guide/advanced.html\n",
    "La palabra labels cambio a codes\n",
    "Changed in version 0.24.0: MultiIndex.labels has been renamed to MultiIndex.codes and MultiIndex.set_labels to MultiIndex.set_codes.\n",
    "'''\n",
    "'''TODO: POR ALGUNA RAZON NO PUEDO EJECUTAR LA MISMA FUNCION DOS VECES. ES COMO SI AFECTARA MIS VARIABLES ORIGINALES'''\n",
    "def delClusters(data,cltodel,idx_cent,idx_cent_sc=[],scl_ord=[],cl_type='cluster'):\n",
    "    '''\n",
    "    Elimina clusters, subclusters, centroides de clusters o centroides de subclusters.\n",
    "        Argumentos:\n",
    "            dataf: dataframes a los que se eliminaran los clusters o subclusters.\n",
    "            cltodel: lista o listas de clusters o subclusters a eliminar\n",
    "            sc_centroids: ista que contiene los centroides. De esta lista se eliminaran los centroides a partir de cltodel.\n",
    "    '''    \n",
    "    dflist =[]\n",
    "    for df in data:\n",
    "        dflist.append(df.drop(cltodel,axis=1))\n",
    "    #cambiar nombre por numero de centroides\n",
    "    n_cl=len(df.columns.levels[0])\n",
    "    n_subcl = len(df.columns.levels[1])\n",
    "    #numero total de clusters incluidos los subclusters\n",
    "    #sn_tot_clusters = (n_subcl*n_cl) -(len(df.columns.labels[0])-len(dflist[0].columns.labels[0]))/2\n",
    "    sn_tot_clusters = (n_subcl*n_cl) -(len(df.columns.codes[0])-len(dflist[0].columns.codes[0]))/2\n",
    "    #eliminar centroides de clusters\n",
    "    clnames = pd.unique(df.columns.get_level_values(0))\n",
    "    lev0 = data[0].columns.get_level_values(0)\n",
    "    lev1 = data[0].columns.get_level_values(1)\n",
    "    namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "    cl_sc_names = namcl[::2]\n",
    "    #convertir a conjuntos\n",
    "    a =set(cltodel)# clusters a eliminar\n",
    "    b=set(cl_sc_names)#nombre de todos los clusters\n",
    "    c=(b-a)#a b lequito a\n",
    "    cent_restantes =set(sorted(set(int(item[0][1:]) for item in c)))#quito la letra C\n",
    "    idx_cent_reales = set(idx_cent.index.values)\n",
    "    idx_cent_todel = list(idx_cent_reales-cent_restantes)\n",
    "    idx_centroids_clean=idx_cent.drop(idx_cent_todel)\n",
    "\n",
    "    #eliminar centroides de los subclusters    \n",
    "    idx_centroidssc_clean = idx_cent_sc.drop(cltodel)\n",
    "  \n",
    "    return dflist,idx_centroids_clean,idx_centroidssc_clean\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# clusters a datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clust2data(dfv,dfvp):\n",
    "    '''\n",
    "    Convierte el dataframe de los datos de vx,vy y potencia separados en clusters (C1-SC1-vx,vy) a datos con \n",
    "    con tres columnas time,vx,vy o time,vv,pw.\n",
    "    To-do:   Sigue perdiendo miles de registros, ¿porque hay registros na en el original?\n",
    "    hay filas con solo nan en el original, en una prueba fueron como 4000'''\n",
    "    dfv= dfv.copy()#para que no afecte el original, si lo afecta el que esta como argumento\n",
    "    dfvp= dfvp.copy()\n",
    "    #Quitar multiindex\n",
    "    dfv.columns = dfv.columns.map(''.join)\n",
    "    dfv.reset_index(inplace=True)\n",
    "    #list comprehension\n",
    "    lvv=[\n",
    "       dfv.iloc[i].dropna().values\n",
    "       for i in range(len(dfv) )      \n",
    "      ]\n",
    "    dfvxvy_clean=pd.DataFrame(lvv,columns=['PCTimeStamp','vx','vy'])\n",
    "    dfvxvy_clean.dropna(inplace=True)#hay filas de nan y se pierden miles de datos, revisar\n",
    "    \n",
    "    #Quitar multiindex\n",
    "    dfvp.columns = dfvp.columns.map(''.join)\n",
    "    dfvp.reset_index(inplace=True)\n",
    "    #list comprehension\n",
    "    lvp=[\n",
    "       dfvp.iloc[i].dropna().values\n",
    "       for i in range(len(dfvp) )      \n",
    "      ]\n",
    "    dfvp_clean=pd.DataFrame(lvp,columns=['PCTimeStamp','vViento','Pw'])\n",
    "    dfvp_clean.dropna(inplace=True)#hay filas de nan y se pierden miles de datos, revisar\n",
    "    \n",
    "    return dfvxvy_clean,dfvp_clean"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
